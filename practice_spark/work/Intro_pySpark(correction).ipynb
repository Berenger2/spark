{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0) Chargement de spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Lire de la donnée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1) Lecture brute\n",
    "\n",
    "Chargez le fichier ville_1.csv dans une variable nommée df.\n",
    "\n",
    "Vous pouvez afficher votre donnée en utilisant la méthode take() ou la methode collect() de l'objet pyspark DataFrame (attention appeler collect() sur un dataframe est déconseillé si vous avez du vrai big data).\n",
    "\n",
    "L'objet possède aussi un attribut appelé dtypes, appelez cet attribut pour obtenir la liste des colonnes et leur type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_c0', 'string'),\n",
       " ('_c1', 'string'),\n",
       " ('_c2', 'string'),\n",
       " ('_c3', 'string'),\n",
       " ('_c4', 'string'),\n",
       " ('_c5', 'string'),\n",
       " ('_c6', 'string'),\n",
       " ('_c7', 'string'),\n",
       " ('_c8', 'string'),\n",
       " ('_c9', 'string'),\n",
       " ('_c10', 'string'),\n",
       " ('_c11', 'string'),\n",
       " ('_c12', 'string')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./data/Villes/ville_1.csv\"\n",
    "# lecture d'un fichier de manière la plus brute\n",
    "df = spark.read.load(path, format=\"csv\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='id', _c1='vitesse_a_pied', _c2='vitesse_a_velo', _c3='home', _c4='travail', _c5='sportif', _c6='casseur', _c7='statut', _c8='salaire', _c9='sexe', _c10='age', _c11='sportivite', _c12='velo_perf_minimale'),\n",
       " Row(_c0='2', _c1='2.344207322136085', _c2='6.251219525696226', _c3='(lon:2.62 lat:2.59)', _c4='(lon:2.34 lat:0.97)', _c5='False', _c6='False', _c7='cadre', _c8='135167.36710061165', _c9='H', _c10='44', _c11='7.814024407120282', _c12='0.4'),\n",
       " Row(_c0='3', _c1='0.02', _c2='0.05', _c3='(lon:3.79 lat:3.81)', _c4='(lon:0.20 lat:0.21)', _c5='False', _c6='False', _c7='technicien_de_surface', _c8='20026.72646423192', _c9='F', _c10='20', _c11='0.1', _c12='0.4'),\n",
       " Row(_c0='4', _c1='0.02', _c2='0.05', _c3='(lon:3.39 lat:0.93)', _c4='(lon:0.58 lat:0.20)', _c5='False', _c6='False', _c7='technicien_de_surface', _c8='15214.584161640825', _c9='F', _c10='35', _c11='0.1', _c12='0.4'),\n",
       " Row(_c0='5', _c1='0.030000000000000006', _c2='0.08', _c3='(lon:2.88 lat:3.78)', _c4='(lon:3.38 lat:2.93)', _c5='False', _c6='False', _c7='technicien_de_surface', _c8='18235.92844960795', _c9='H', _c10='71', _c11='0.1', _c12='0.4')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2) Lecture avec les entêtes\n",
    "\n",
    "Recharger le même fichier mais cette fois-ci utilisez l'option header pour rajouter les noms de colonnes à votre df.\n",
    "\n",
    "Appelez l'attribut dtypes et comparez la sortie avec celle de la lecture brute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'string'),\n",
       " ('vitesse_a_pied', 'string'),\n",
       " ('vitesse_a_velo', 'string'),\n",
       " ('home', 'string'),\n",
       " ('travail', 'string'),\n",
       " ('sportif', 'string'),\n",
       " ('casseur', 'string'),\n",
       " ('statut', 'string'),\n",
       " ('salaire', 'string'),\n",
       " ('sexe', 'string'),\n",
       " ('age', 'string'),\n",
       " ('sportivite', 'string'),\n",
       " ('velo_perf_minimale', 'string')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# l'option 'header' permet de rajouter les noms des colonnes \n",
    "df = spark.read.format('csv').options(header=True).load(path)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id='2', vitesse_a_pied='2.344207322136085', vitesse_a_velo='6.251219525696226', home='(lon:2.62 lat:2.59)', travail='(lon:2.34 lat:0.97)', sportif='False', casseur='False', statut='cadre', salaire='135167.36710061165', sexe='H', age='44', sportivite='7.814024407120282', velo_perf_minimale='0.4'),\n",
       " Row(id='3', vitesse_a_pied='0.02', vitesse_a_velo='0.05', home='(lon:3.79 lat:3.81)', travail='(lon:0.20 lat:0.21)', sportif='False', casseur='False', statut='technicien_de_surface', salaire='20026.72646423192', sexe='F', age='20', sportivite='0.1', velo_perf_minimale='0.4'),\n",
       " Row(id='4', vitesse_a_pied='0.02', vitesse_a_velo='0.05', home='(lon:3.39 lat:0.93)', travail='(lon:0.58 lat:0.20)', sportif='False', casseur='False', statut='technicien_de_surface', salaire='15214.584161640825', sexe='F', age='35', sportivite='0.1', velo_perf_minimale='0.4'),\n",
       " Row(id='5', vitesse_a_pied='0.030000000000000006', vitesse_a_velo='0.08', home='(lon:2.88 lat:3.78)', travail='(lon:3.38 lat:2.93)', sportif='False', casseur='False', statut='technicien_de_surface', salaire='18235.92844960795', sexe='H', age='71', sportivite='0.1', velo_perf_minimale='0.4'),\n",
       " Row(id='6', vitesse_a_pied='0.02', vitesse_a_velo='0.05', home='(lon:0.44 lat:1.45)', travail='(lon:1.85 lat:0.04)', sportif='False', casseur='False', statut='professeur', salaire='30852.120709809133', sexe='F', age='79', sportivite='0.1', velo_perf_minimale='0.4'),\n",
       " Row(id='7', vitesse_a_pied='0.9726853575358816', vitesse_a_velo='2.431713393839704', home='(lon:0.18 lat:2.60)', travail='(lon:2.16 lat:2.28)', sportif='False', casseur='False', statut='employe', salaire='54494.87538632937', sexe='F', age='46', sportivite='4.863426787679408', velo_perf_minimale='0.4'),\n",
       " Row(id='8', vitesse_a_pied='0.24473592541818706', vitesse_a_velo='0.6526291344484989', home='(lon:1.67 lat:0.17)', travail='(lon:2.19 lat:1.90)', sportif='False', casseur='False', statut='technicien_de_surface', salaire='33597.687351868175', sexe='H', age='63', sportivite='0.8157864180606236', velo_perf_minimale='0.4'),\n",
       " Row(id='9', vitesse_a_pied='0.6295531740219638', vitesse_a_velo='1.5738829350549093', home='(lon:2.16 lat:2.32)', travail='(lon:3.44 lat:3.54)', sportif='False', casseur='False', statut='technicien_de_surface', salaire='11799.927798039249', sexe='F', age='65', sportivite='3.1477658701098186', velo_perf_minimale='0.4'),\n",
       " Row(id='10', vitesse_a_pied='0.3385617496874321', vitesse_a_velo='0.9028313324998192', home='(lon:2.16 lat:2.98)', travail='(lon:2.34 lat:2.56)', sportif='False', casseur='False', statut='professeur', salaire='33131.88170893892', sexe='H', age='32', sportivite='1.128539165624774', velo_perf_minimale='0.4'),\n",
       " Row(id='11', vitesse_a_pied='0.25214291732243804', vitesse_a_velo='0.630357293306095', home='(lon:0.28 lat:2.44)', travail='(lon:1.28 lat:1.40)', sportif='False', casseur='False', statut='employe', salaire='53716.3729157698', sexe='F', age='21', sportivite='1.26071458661219', velo_perf_minimale='0.4'),\n",
       " Row(id='12', vitesse_a_pied='0.030000000000000006', vitesse_a_velo='0.08', home='(lon:2.07 lat:1.24)', travail='(lon:2.62 lat:2.41)', sportif='False', casseur='False', statut='éboueur', salaire='25445.75075327384', sexe='H', age='34', sportivite='0.1', velo_perf_minimale='0.4'),\n",
       " Row(id='13', vitesse_a_pied='1.0436625537904385', vitesse_a_velo='2.7831001434411684', home='(lon:3.90 lat:0.62)', travail='(lon:3.29 lat:3.86)', sportif='False', casseur='False', statut='reserviste', salaire='35065.42961851433', sexe='H', age='37', sportivite='3.4788751793014607', velo_perf_minimale='0.4'),\n",
       " Row(id='14', vitesse_a_pied='0.3733552690301726', vitesse_a_velo='0.9333881725754316', home='(lon:3.87 lat:3.74)', travail='(lon:0.41 lat:0.36)', sportif='False', casseur='False', statut='cadre', salaire='74308.6319691613', sexe='F', age='34', sportivite='1.866776345150863', velo_perf_minimale='0.4'),\n",
       " Row(id='15', vitesse_a_pied='0.030000000000000006', vitesse_a_velo='0.08', home='(lon:0.73 lat:0.21)', travail='(lon:3.30 lat:0.34)', sportif='False', casseur='False', statut='cadre', salaire='50740.88071802778', sexe='H', age='34', sportivite='0.1', velo_perf_minimale='0.4'),\n",
       " Row(id='16', vitesse_a_pied='0.02', vitesse_a_velo='0.05', home='(lon:1.37 lat:1.09)', travail='(lon:0.45 lat:1.77)', sportif='False', casseur='False', statut='éboueur', salaire='21040.289070523115', sexe='F', age='32', sportivite='0.1', velo_perf_minimale='0.4'),\n",
       " Row(id='17', vitesse_a_pied='1.0608622097751907', vitesse_a_velo='2.6521555244379766', home='(lon:3.68 lat:0.79)', travail='(lon:2.67 lat:3.66)', sportif='False', casseur='False', statut='technicien_de_surface', salaire='16946.365288912493', sexe='F', age='16', sportivite='5.304311048875953', velo_perf_minimale='0.4'),\n",
       " Row(id='18', vitesse_a_pied='0.02', vitesse_a_velo='0.05', home='(lon:0.51 lat:2.32)', travail='(lon:1.01 lat:0.40)', sportif='False', casseur='False', statut='technicien_de_surface', salaire='22099.145463261266', sexe='F', age='24', sportivite='0.1', velo_perf_minimale='0.4'),\n",
       " Row(id='19', vitesse_a_pied='0.9773845017525072', vitesse_a_velo='2.6063586713400198', home='(lon:1.70 lat:1.94)', travail='(lon:0.28 lat:1.85)', sportif='False', casseur='False', statut='cadre', salaire='83399.49945220708', sexe='H', age='40', sportivite='3.257948339175024', velo_perf_minimale='0.4'),\n",
       " Row(id='20', vitesse_a_pied='0.0820881445834403', vitesse_a_velo='0.21890171888917406', home='(lon:1.72 lat:2.95)', travail='(lon:2.65 lat:1.68)', sportif='False', casseur='False', statut='cadre', salaire='78429.53192610192', sexe='H', age='74', sportivite='0.27362714861146764', velo_perf_minimale='0.4'),\n",
       " Row(id='21', vitesse_a_pied='0.2944550644296354', vitesse_a_velo='0.7852135051456944', home='(lon:2.57 lat:0.11)', travail='(lon:3.75 lat:0.54)', sportif='False', casseur='False', statut='cadre', salaire='75877.5189863671', sexe='H', age='83', sportivite='0.981516881432118', velo_perf_minimale='0.4')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3) Lecture avec les types détectés automatiquement\n",
    "\n",
    "Recharger le fichier avec  l'option inferShema.\n",
    "\n",
    "L'option 'inferSchema' permet de transformer les colonnes en types plus précis : entier  / booléens / chaines de caractères... bien sûr spark trouve les types uniquement si le fichier d'origine permet de les trouver de manière simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'int'),\n",
       " ('vitesse_a_pied', 'double'),\n",
       " ('vitesse_a_velo', 'double'),\n",
       " ('home', 'string'),\n",
       " ('travail', 'string'),\n",
       " ('sportif', 'boolean'),\n",
       " ('casseur', 'boolean'),\n",
       " ('statut', 'string'),\n",
       " ('salaire', 'double'),\n",
       " ('sexe', 'string'),\n",
       " ('age', 'int'),\n",
       " ('sportivite', 'double'),\n",
       " ('velo_perf_minimale', 'double')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# l'option 'inferSchema' permet de transformer les colonnes en \n",
    "# types plus précis : entier  / booléens / chaines de caractères...\n",
    "# bien sûr spark trouve les types uniquement si le fichier d'origine\n",
    "# permet de les trouver de manière simple\n",
    "df = spark.read.format('csv').options(header=True, inferSchema=True).load(path)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-------------------+-------------------+-------------------+-------+-------+--------------------+------------------+----+---+-------------------+------------------+\n",
      "| id|      vitesse_a_pied|     vitesse_a_velo|               home|            travail|sportif|casseur|              statut|           salaire|sexe|age|         sportivite|velo_perf_minimale|\n",
      "+---+--------------------+-------------------+-------------------+-------------------+-------+-------+--------------------+------------------+----+---+-------------------+------------------+\n",
      "|  2|   2.344207322136085|  6.251219525696226|(lon:2.62 lat:2.59)|(lon:2.34 lat:0.97)|  false|  false|               cadre|135167.36710061165|   H| 44|  7.814024407120282|               0.4|\n",
      "|  3|                0.02|               0.05|(lon:3.79 lat:3.81)|(lon:0.20 lat:0.21)|  false|  false|technicien_de_sur...| 20026.72646423192|   F| 20|                0.1|               0.4|\n",
      "|  4|                0.02|               0.05|(lon:3.39 lat:0.93)|(lon:0.58 lat:0.20)|  false|  false|technicien_de_sur...|15214.584161640825|   F| 35|                0.1|               0.4|\n",
      "|  5|0.030000000000000006|               0.08|(lon:2.88 lat:3.78)|(lon:3.38 lat:2.93)|  false|  false|technicien_de_sur...| 18235.92844960795|   H| 71|                0.1|               0.4|\n",
      "|  6|                0.02|               0.05|(lon:0.44 lat:1.45)|(lon:1.85 lat:0.04)|  false|  false|          professeur|30852.120709809133|   F| 79|                0.1|               0.4|\n",
      "|  7|  0.9726853575358816|  2.431713393839704|(lon:0.18 lat:2.60)|(lon:2.16 lat:2.28)|  false|  false|             employe| 54494.87538632937|   F| 46|  4.863426787679408|               0.4|\n",
      "|  8| 0.24473592541818706| 0.6526291344484989|(lon:1.67 lat:0.17)|(lon:2.19 lat:1.90)|  false|  false|technicien_de_sur...|33597.687351868175|   H| 63| 0.8157864180606236|               0.4|\n",
      "|  9|  0.6295531740219638| 1.5738829350549093|(lon:2.16 lat:2.32)|(lon:3.44 lat:3.54)|  false|  false|technicien_de_sur...|11799.927798039249|   F| 65| 3.1477658701098186|               0.4|\n",
      "| 10|  0.3385617496874321| 0.9028313324998192|(lon:2.16 lat:2.98)|(lon:2.34 lat:2.56)|  false|  false|          professeur| 33131.88170893892|   H| 32|  1.128539165624774|               0.4|\n",
      "| 11| 0.25214291732243804|  0.630357293306095|(lon:0.28 lat:2.44)|(lon:1.28 lat:1.40)|  false|  false|             employe|  53716.3729157698|   F| 21|   1.26071458661219|               0.4|\n",
      "| 12|0.030000000000000006|               0.08|(lon:2.07 lat:1.24)|(lon:2.62 lat:2.41)|  false|  false|             éboueur| 25445.75075327384|   H| 34|                0.1|               0.4|\n",
      "| 13|  1.0436625537904385| 2.7831001434411684|(lon:3.90 lat:0.62)|(lon:3.29 lat:3.86)|  false|  false|          reserviste| 35065.42961851433|   H| 37| 3.4788751793014607|               0.4|\n",
      "| 14|  0.3733552690301726| 0.9333881725754316|(lon:3.87 lat:3.74)|(lon:0.41 lat:0.36)|  false|  false|               cadre|  74308.6319691613|   F| 34|  1.866776345150863|               0.4|\n",
      "| 15|0.030000000000000006|               0.08|(lon:0.73 lat:0.21)|(lon:3.30 lat:0.34)|  false|  false|               cadre| 50740.88071802778|   H| 34|                0.1|               0.4|\n",
      "| 16|                0.02|               0.05|(lon:1.37 lat:1.09)|(lon:0.45 lat:1.77)|  false|  false|             éboueur|21040.289070523115|   F| 32|                0.1|               0.4|\n",
      "| 17|  1.0608622097751907| 2.6521555244379766|(lon:3.68 lat:0.79)|(lon:2.67 lat:3.66)|  false|  false|technicien_de_sur...|16946.365288912493|   F| 16|  5.304311048875953|               0.4|\n",
      "| 18|                0.02|               0.05|(lon:0.51 lat:2.32)|(lon:1.01 lat:0.40)|  false|  false|technicien_de_sur...|22099.145463261266|   F| 24|                0.1|               0.4|\n",
      "| 19|  0.9773845017525072| 2.6063586713400198|(lon:1.70 lat:1.94)|(lon:0.28 lat:1.85)|  false|  false|               cadre| 83399.49945220708|   H| 40|  3.257948339175024|               0.4|\n",
      "| 20|  0.0820881445834403|0.21890171888917406|(lon:1.72 lat:2.95)|(lon:2.65 lat:1.68)|  false|  false|               cadre| 78429.53192610192|   H| 74|0.27362714861146764|               0.4|\n",
      "| 21|  0.2944550644296354| 0.7852135051456944|(lon:2.57 lat:0.11)|(lon:3.75 lat:0.54)|  false|  false|               cadre|  75877.5189863671|   H| 83|  0.981516881432118|               0.4|\n",
      "+---+--------------------+-------------------+-------------------+-------------------+-------+-------+--------------------+------------------+----+---+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4) L'attribut schema\n",
    "\n",
    "Il vous permet d'afficher le schéma de votre df, avec pour chaque colonne son nom, son type, et si elle accepte les valeurs nulles ou non. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('id', IntegerType(), True), StructField('vitesse_a_pied', DoubleType(), True), StructField('vitesse_a_velo', DoubleType(), True), StructField('home', StringType(), True), StructField('travail', StringType(), True), StructField('sportif', BooleanType(), True), StructField('casseur', BooleanType(), True), StructField('statut', StringType(), True), StructField('salaire', DoubleType(), True), StructField('sexe', StringType(), True), StructField('age', IntegerType(), True), StructField('sportivite', DoubleType(), True), StructField('velo_perf_minimale', DoubleType(), True)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous avez aussi la méthode printSchema() qui permet d'afficher le shéma du df de manière plus lisible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- vitesse_a_pied: double (nullable = true)\n",
      " |-- vitesse_a_velo: double (nullable = true)\n",
      " |-- home: string (nullable = true)\n",
      " |-- travail: string (nullable = true)\n",
      " |-- sportif: boolean (nullable = true)\n",
      " |-- casseur: boolean (nullable = true)\n",
      " |-- statut: string (nullable = true)\n",
      " |-- salaire: double (nullable = true)\n",
      " |-- sexe: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- sportivite: double (nullable = true)\n",
      " |-- velo_perf_minimale: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Ecriture de la dataframe sur le disque\n",
    "\n",
    "Sauvegardez le df sous différents formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1) choix du format : csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[PATH_ALREADY_EXISTS] Path file:/home/jovyan/work/data/Villes/csv already exists. Set mode as \"overwrite\" to overwrite the existing path.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./data/Villes/csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/readwriter.py:1463\u001b[0m, in \u001b[0;36mDataFrameWriter.save\u001b[0;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m   1461\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jwrite\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1463\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [PATH_ALREADY_EXISTS] Path file:/home/jovyan/work/data/Villes/csv already exists. Set mode as \"overwrite\" to overwrite the existing path."
     ]
    }
   ],
   "source": [
    "df.write.format(\"csv\").save(\"./data/Villes/csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2) choix du format : parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[PATH_ALREADY_EXISTS] Path file:/home/jovyan/work/data/Villes/parquet already exists. Set mode as \"overwrite\" to overwrite the existing path.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./data/Villes/parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/readwriter.py:1463\u001b[0m, in \u001b[0;36mDataFrameWriter.save\u001b[0;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m   1461\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jwrite\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1463\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [PATH_ALREADY_EXISTS] Path file:/home/jovyan/work/data/Villes/parquet already exists. Set mode as \"overwrite\" to overwrite the existing path."
     ]
    }
   ],
   "source": [
    "df.write.format(\"parquet\").save(\"./data/Villes/parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3) choix du format : json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[PATH_ALREADY_EXISTS] Path file:/home/jovyan/work/data/Villes/ville already exists. Set mode as \"overwrite\" to overwrite the existing path.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./data/Villes/ville\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjson\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/readwriter.py:1463\u001b[0m, in \u001b[0;36mDataFrameWriter.save\u001b[0;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m   1461\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jwrite\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1463\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [PATH_ALREADY_EXISTS] Path file:/home/jovyan/work/data/Villes/ville already exists. Set mode as \"overwrite\" to overwrite the existing path."
     ]
    }
   ],
   "source": [
    "df.write.save(\"./data/Villes/ville\", format=\"json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4) Lecture de différents formats\n",
    "\n",
    "Vous pouvez choisir de lire le df sous un format ou un autre en utilisant l'argument format dans la fonction spark.read.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part-00000-450d104d-9209-4c90-b4d6-87f0a60978e3-c000.json  _SUCCESS\n"
     ]
    }
   ],
   "source": [
    "# le ! vous permet d'executer des commandes dans votre terminal depuis le notebook\n",
    "!ls ./data/Villes/ville/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json = spark.read.load(\"./data/Villes/ville/\", format=\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parquet = spark.read.load(\"./data/Villes/parquet\", format=\"parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Calculer des résultats : les actions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1) Nombre de lignes : count\n",
    "\n",
    "Chargez les fichiers csv contenus dans le dossiers ./data/Cyclistes/ dans un df nommé cyclistes, puis comptez les lignes du dataframe obtenu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2232000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyclistes = spark.read.load(\"./data/Cyclistes/\", format=\"csv\", header=True, inferSchema=\"True\")\n",
    "cyclistes.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afficher le schéma de ce nouveau df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- sur_velo: boolean (nullable = true)\n",
      " |-- velo: string (nullable = true)\n",
      " |-- vitesse: double (nullable = true)\n",
      " |-- position: string (nullable = true)\n",
      " |-- destination_finale: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cyclistes.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichez 10 lignes du df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=12, timestamp=datetime.datetime(2018, 1, 1, 0, 1), sur_velo=False, velo='False', vitesse=0.030000000000000006, position='(lon:2.07 lat:1.24)', destination_finale='False'),\n",
       " Row(id=12, timestamp=datetime.datetime(2018, 1, 1, 0, 2), sur_velo=False, velo='False', vitesse=0.030000000000000006, position='(lon:2.07 lat:1.24)', destination_finale='False'),\n",
       " Row(id=12, timestamp=datetime.datetime(2018, 1, 1, 0, 3), sur_velo=False, velo='False', vitesse=0.030000000000000006, position='(lon:2.07 lat:1.24)', destination_finale='False'),\n",
       " Row(id=12, timestamp=datetime.datetime(2018, 1, 1, 0, 4), sur_velo=False, velo='False', vitesse=0.030000000000000006, position='(lon:2.07 lat:1.24)', destination_finale='False'),\n",
       " Row(id=12, timestamp=datetime.datetime(2018, 1, 1, 0, 5), sur_velo=False, velo='False', vitesse=0.030000000000000006, position='(lon:2.07 lat:1.24)', destination_finale='False'),\n",
       " Row(id=12, timestamp=datetime.datetime(2018, 1, 1, 0, 6), sur_velo=False, velo='False', vitesse=0.030000000000000006, position='(lon:2.07 lat:1.24)', destination_finale='False'),\n",
       " Row(id=12, timestamp=datetime.datetime(2018, 1, 1, 0, 7), sur_velo=False, velo='False', vitesse=0.030000000000000006, position='(lon:2.07 lat:1.24)', destination_finale='False'),\n",
       " Row(id=12, timestamp=datetime.datetime(2018, 1, 1, 0, 8), sur_velo=False, velo='False', vitesse=0.030000000000000006, position='(lon:2.07 lat:1.24)', destination_finale='False'),\n",
       " Row(id=12, timestamp=datetime.datetime(2018, 1, 1, 0, 9), sur_velo=False, velo='False', vitesse=0.030000000000000006, position='(lon:2.07 lat:1.24)', destination_finale='False'),\n",
       " Row(id=12, timestamp=datetime.datetime(2018, 1, 1, 0, 10), sur_velo=False, velo='False', vitesse=0.030000000000000006, position='(lon:2.07 lat:1.24)', destination_finale='False')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyclistes.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2) Moyenne : agg + colonne + mean\n",
    "\n",
    "A l'aide de la méthode agg(), calculez la moyenne sur la colonne vitesse.\n",
    "\n",
    "Vous pouvez récuperer le résultat avec la méthode collect()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(avg(vitesse)=0.4423137463995158)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyclistes.agg({\"vitesse\" : \"mean\"}).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3) Quantile approximatifs pour gagner du temps de calcul\n",
    "\n",
    "En statistiques et en théorie des probabilités, les quantiles sont les valeurs qui divisent un jeu de données en intervalles contenant le même nombre de données. Il y a donc un quantile de moins que le nombre de groupes créés. Ainsi les quartiles sont les trois quantiles qui divisent un ensemble de données en quatre groupes de taille égale.\n",
    "\n",
    "La méthode approxQuantile permet de laisser une tolérance a l'erreur ce qui réduit le temps de calul sur d'énormes jeux de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcul_quantile(df, erreur_acceptee):/\n",
    "    debut            = time.time()\n",
    "    colonne          = \"vitesse\"\n",
    "    quantiles_voulus = [0.25, 0.50, 0.75]\n",
    "    resultat         =  df.approxQuantile(colonne, quantiles_voulus , erreur_acceptee )\n",
    "    fin              = time.time()\n",
    "    delais           = fin -debut\n",
    "    print (\"delais =%.2f sec, quantiles = %s\"%(delais, resultat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delais =3.53 sec, quantiles = [0.030000000000000006, 0.2973786407359121, 0.6467173919199576]\n"
     ]
    }
   ],
   "source": [
    "calcul_quantile(cyclistes, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delais =2.71 sec, quantiles = [0.030000000000000006, 0.2973786407359121, 0.6295531740219638]\n"
     ]
    }
   ],
   "source": [
    "calcul_quantile(cyclistes, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delais =7.34 sec, quantiles = [0.030000000000000006, 0.3283952876721612, 0.6295531740219638]\n"
     ]
    }
   ],
   "source": [
    "calcul_quantile(cyclistes, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload de la dataframe villes\n",
    "\n",
    "Chargez le fichier villes dans un df nommé villes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- vitesse_a_pied: double (nullable = true)\n",
      " |-- vitesse_a_velo: double (nullable = true)\n",
      " |-- home: string (nullable = true)\n",
      " |-- travail: string (nullable = true)\n",
      " |-- sportif: boolean (nullable = true)\n",
      " |-- casseur: boolean (nullable = true)\n",
      " |-- statut: string (nullable = true)\n",
      " |-- salaire: double (nullable = true)\n",
      " |-- sexe: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- sportivite: double (nullable = true)\n",
      " |-- velo_perf_minimale: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "villes =spark.read.load(\"./data/Villes/\", format=\"csv\", header=True, inferSchema=\"True\")\n",
    "villes.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+------------------+-------------------+-------------------+-------+-------+--------------------+------------------+----+---+------------------+------------------+\n",
      "| id|      vitesse_a_pied|    vitesse_a_velo|               home|            travail|sportif|casseur|              statut|           salaire|sexe|age|        sportivite|velo_perf_minimale|\n",
      "+---+--------------------+------------------+-------------------+-------------------+-------+-------+--------------------+------------------+----+---+------------------+------------------+\n",
      "|  2|   2.344207322136085| 6.251219525696226|(lon:2.62 lat:2.59)|(lon:2.34 lat:0.97)|  false|  false|               cadre|135167.36710061165|   H| 44| 7.814024407120282|               0.4|\n",
      "|  3|                0.02|              0.05|(lon:3.79 lat:3.81)|(lon:0.20 lat:0.21)|  false|  false|technicien_de_sur...| 20026.72646423192|   F| 20|               0.1|               0.4|\n",
      "|  4|                0.02|              0.05|(lon:3.39 lat:0.93)|(lon:0.58 lat:0.20)|  false|  false|technicien_de_sur...|15214.584161640825|   F| 35|               0.1|               0.4|\n",
      "|  5|0.030000000000000006|              0.08|(lon:2.88 lat:3.78)|(lon:3.38 lat:2.93)|  false|  false|technicien_de_sur...| 18235.92844960795|   H| 71|               0.1|               0.4|\n",
      "|  6|                0.02|              0.05|(lon:0.44 lat:1.45)|(lon:1.85 lat:0.04)|  false|  false|          professeur|30852.120709809133|   F| 79|               0.1|               0.4|\n",
      "|  7|  0.9726853575358816| 2.431713393839704|(lon:0.18 lat:2.60)|(lon:2.16 lat:2.28)|  false|  false|             employe| 54494.87538632937|   F| 46| 4.863426787679408|               0.4|\n",
      "|  8| 0.24473592541818706|0.6526291344484989|(lon:1.67 lat:0.17)|(lon:2.19 lat:1.90)|  false|  false|technicien_de_sur...|33597.687351868175|   H| 63|0.8157864180606236|               0.4|\n",
      "|  9|  0.6295531740219638|1.5738829350549093|(lon:2.16 lat:2.32)|(lon:3.44 lat:3.54)|  false|  false|technicien_de_sur...|11799.927798039249|   F| 65|3.1477658701098186|               0.4|\n",
      "| 10|  0.3385617496874321|0.9028313324998192|(lon:2.16 lat:2.98)|(lon:2.34 lat:2.56)|  false|  false|          professeur| 33131.88170893892|   H| 32| 1.128539165624774|               0.4|\n",
      "| 11| 0.25214291732243804| 0.630357293306095|(lon:0.28 lat:2.44)|(lon:1.28 lat:1.40)|  false|  false|             employe|  53716.3729157698|   F| 21|  1.26071458661219|               0.4|\n",
      "+---+--------------------+------------------+-------------------+-------------------+-------+-------+--------------------+------------------+----+---+------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "villes.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4) corrélation\n",
    "\n",
    "En probabilités et en statistique, la corrélation entre plusieurs variables aléatoires ou statistiques est une notion de liaison qui contredit leur indépendance.\n",
    "\n",
    "Calculez la corrélation entre les colonnes age et vitesse_a_velo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.06411845578664936"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villes.corr(\"age\", \"vitesse_a_velo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5) covariance\n",
    "\n",
    "La covariance entre deux variables aléatoires est un nombre permettant de quantifier leurs écarts conjoints par rapport à leurs espérances respectives. Elle s’utilise également pour deux séries de données numériques (écarts par rapport aux moyennes).\n",
    "La covariance est une extension de la notion de variance. La corrélation est une forme normalisée de la covariance.\n",
    "\n",
    "Calculez la covariance entre les colonnes age et vitesse_a_velo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.5721945755314064"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villes.cov(\"age\", \"vitesse_a_velo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6) sample\n",
    "\n",
    "La méthode sample() permet de tirer aléatoirement une fraction du dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villes.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villes_1_pct = villes.sample(False, 0.1, seed=42)\n",
    "villes_1_pct.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=9, vitesse_a_pied=0.6295531740219638, vitesse_a_velo=1.5738829350549093, home='(lon:2.16 lat:2.32)', travail='(lon:3.44 lat:3.54)', sportif=False, casseur=False, statut='technicien_de_surface', salaire=11799.927798039249, sexe='F', age=65, sportivite=3.1477658701098186, velo_perf_minimale=0.4),\n",
       " Row(id=18, vitesse_a_pied=0.02, vitesse_a_velo=0.05, home='(lon:0.51 lat:2.32)', travail='(lon:1.01 lat:0.40)', sportif=False, casseur=False, statut='technicien_de_surface', salaire=22099.145463261266, sexe='F', age=24, sportivite=0.1, velo_perf_minimale=0.4),\n",
       " Row(id=20, vitesse_a_pied=0.0820881445834403, vitesse_a_velo=0.21890171888917406, home='(lon:1.72 lat:2.95)', travail='(lon:2.65 lat:1.68)', sportif=False, casseur=False, statut='cadre', salaire=78429.53192610192, sexe='H', age=74, sportivite=0.27362714861146764, velo_perf_minimale=0.4)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villes_1_pct.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villes.exceptAll(villes_1_pct).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7) filter \n",
    "\n",
    "La méthode filter() permet le df selon certaines valeurs dans les colonnes.\n",
    "\n",
    "Utilisez cette méthode pour récuperer seulement les lignes avec le sexe féminin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "villesF = villes.filter(villes[\"sexe\"]==\"F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "villesF1 = villes.filter((villes.sexe==\"F\")&(villes.statut=='éboueur'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villesF1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villesF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=3, vitesse_a_pied=0.02, vitesse_a_velo=0.05, home='(lon:3.79 lat:3.81)', travail='(lon:0.20 lat:0.21)', sportif=False, casseur=False, statut='technicien_de_surface', salaire=20026.72646423192, sexe='F', age=20, sportivite=0.1, velo_perf_minimale=0.4),\n",
       " Row(id=4, vitesse_a_pied=0.02, vitesse_a_velo=0.05, home='(lon:3.39 lat:0.93)', travail='(lon:0.58 lat:0.20)', sportif=False, casseur=False, statut='technicien_de_surface', salaire=15214.584161640825, sexe='F', age=35, sportivite=0.1, velo_perf_minimale=0.4),\n",
       " Row(id=6, vitesse_a_pied=0.02, vitesse_a_velo=0.05, home='(lon:0.44 lat:1.45)', travail='(lon:1.85 lat:0.04)', sportif=False, casseur=False, statut='professeur', salaire=30852.120709809133, sexe='F', age=79, sportivite=0.1, velo_perf_minimale=0.4),\n",
       " Row(id=7, vitesse_a_pied=0.9726853575358816, vitesse_a_velo=2.431713393839704, home='(lon:0.18 lat:2.60)', travail='(lon:2.16 lat:2.28)', sportif=False, casseur=False, statut='employe', salaire=54494.87538632937, sexe='F', age=46, sportivite=4.863426787679408, velo_perf_minimale=0.4),\n",
       " Row(id=9, vitesse_a_pied=0.6295531740219638, vitesse_a_velo=1.5738829350549093, home='(lon:2.16 lat:2.32)', travail='(lon:3.44 lat:3.54)', sportif=False, casseur=False, statut='technicien_de_surface', salaire=11799.927798039249, sexe='F', age=65, sportivite=3.1477658701098186, velo_perf_minimale=0.4),\n",
       " Row(id=11, vitesse_a_pied=0.25214291732243804, vitesse_a_velo=0.630357293306095, home='(lon:0.28 lat:2.44)', travail='(lon:1.28 lat:1.40)', sportif=False, casseur=False, statut='employe', salaire=53716.3729157698, sexe='F', age=21, sportivite=1.26071458661219, velo_perf_minimale=0.4),\n",
       " Row(id=14, vitesse_a_pied=0.3733552690301726, vitesse_a_velo=0.9333881725754316, home='(lon:3.87 lat:3.74)', travail='(lon:0.41 lat:0.36)', sportif=False, casseur=False, statut='cadre', salaire=74308.6319691613, sexe='F', age=34, sportivite=1.866776345150863, velo_perf_minimale=0.4),\n",
       " Row(id=16, vitesse_a_pied=0.02, vitesse_a_velo=0.05, home='(lon:1.37 lat:1.09)', travail='(lon:0.45 lat:1.77)', sportif=False, casseur=False, statut='éboueur', salaire=21040.289070523115, sexe='F', age=32, sportivite=0.1, velo_perf_minimale=0.4),\n",
       " Row(id=17, vitesse_a_pied=1.0608622097751907, vitesse_a_velo=2.6521555244379766, home='(lon:3.68 lat:0.79)', travail='(lon:2.67 lat:3.66)', sportif=False, casseur=False, statut='technicien_de_surface', salaire=16946.365288912493, sexe='F', age=16, sportivite=5.304311048875953, velo_perf_minimale=0.4),\n",
       " Row(id=18, vitesse_a_pied=0.02, vitesse_a_velo=0.05, home='(lon:0.51 lat:2.32)', travail='(lon:1.01 lat:0.40)', sportif=False, casseur=False, statut='technicien_de_surface', salaire=22099.145463261266, sexe='F', age=24, sportivite=0.1, velo_perf_minimale=0.4)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villesF.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peux aussi filtrer le df avec la méthode where(). Filtrez le df de la même façon que precedemment en utilisant cette méthode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villes.where((villes.sexe==\"F\")&(villes.statut=='éboueur')).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Transformer la données : les transformations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations : demandent à être suivi par un collect ou une action (count par exemple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1) Obtenir des statistiques sur les colonnes numériques\n",
    "\n",
    "La méthode describe() permet de calculer les statistiques récapitulatives d'une ou plusieurs colonnes numériques dans un df. Si le nom des colonnes n'est pas spécifié, la méthode calculera des statistiques récapitulatives pour toutes les colonnes numériques présentes dans le df.\n",
    "\n",
    "Afficher les statistiques de la colonne age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(summary='count', age='50'),\n",
       " Row(summary='mean', age='48.4'),\n",
       " Row(summary='stddev', age='19.79898987322333'),\n",
       " Row(summary='min', age='16'),\n",
       " Row(summary='max', age='83')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villes.describe('age').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|              age|\n",
      "+-------+-----------------+\n",
      "|  count|               50|\n",
      "|   mean|             48.4|\n",
      "| stddev|19.79898987322333|\n",
      "|    min|               16|\n",
      "|    max|               83|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "villes.describe([\"age\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2) groupby\n",
    "\n",
    "La méthode groupBy() suivie de la methode agg() permet de grouper le df selon les catgories d'une ou plusieurs colonnes pour faire des calculs sur ces catégories.\n",
    "\n",
    "Calculez la moyenne de la colonnes sportivité selon le sexe des personnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|sexe|   avg(sportivite)|\n",
      "+----+------------------+\n",
      "|   F|1.8410619134680517|\n",
      "|   H|1.6356186755623958|\n",
      "+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "villes.groupBy(\"sexe\").agg({\"sportivite\" : \"mean\"}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculez la moyenne de la colonne age et la valeur max de la colonne sportivité par sexe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+------------------+------------------+\n",
      "|sexe|              statut|   max(sportivite)|          avg(age)|\n",
      "+----+--------------------+------------------+------------------+\n",
      "|   H|          reserviste|3.4788751793014607|              48.0|\n",
      "|   H|             éboueur| 1.946331143388495|             35.25|\n",
      "|   F|          reserviste|0.9222269402110364|              62.5|\n",
      "|   H|          professeur| 4.726124323688307|              48.2|\n",
      "|   F|               cadre| 1.866776345150863|              34.0|\n",
      "|   F|             éboueur|2.8263443880278643|              44.0|\n",
      "|   H|technicien_de_sur...|1.7382637294042846|              62.0|\n",
      "|   F|             employe| 4.863426787679408|47.166666666666664|\n",
      "|   H|               cadre| 7.814024407120282|              50.6|\n",
      "|   F|          professeur|               0.1|              70.0|\n",
      "|   F|technicien_de_sur...| 5.304311048875953|             37.25|\n",
      "+----+--------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "villes.groupBy([\"sexe\",\"statut\"]).agg({\"sportivite\" : \"max\", \"age\":\"mean\"}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculez la moyenne des colonnes vitesse_a_pied et vitesse_a_velo par sexe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(sexe='F', avg(vitesse_a_velo)=0.9205309567340259, avg(vitesse_a_pied)=0.36821238269361034),\n",
       " Row(sexe='H', avg(vitesse_a_velo)=1.3084949404499162, avg(vitesse_a_pied)=0.4906856026687184)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villes.groupBy(\"sexe\").agg({\"vitesse_a_pied\" : \"mean\", \"vitesse_a_velo\":\"mean\"}).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3) summary\n",
    "\n",
    "La méthode summary() permet des faire des calculs statistiques de base sur toutes les colonnes du df.\n",
    "\n",
    "Appliquez un count et un max sur toutes les colonnes du df et afficher les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(summary='mean', id='26.5', vitesse_a_pied='0.4392468502791733', vitesse_a_velo='1.145550067289242', home=None, travail=None, statut=None, salaire='40143.21200936129', sexe=None, age='48.4', sportivite='1.721904835482771', velo_perf_minimale='0.39999999999999986'),\n",
       " Row(summary='stddev', id='14.577379737113251', vitesse_a_pied='0.46957482160828645', vitesse_a_velo='1.2384549280855548', home=None, travail=None, statut=None, salaire='32900.934492297645', sexe=None, age='19.79898987322333', sportivite='1.7739858396475683', velo_perf_minimale='0.0')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villes.summary(\"mean\", \"stddev\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(statut='reserviste'),\n",
       " Row(statut='cadre'),\n",
       " Row(statut='employe'),\n",
       " Row(statut='technicien_de_surface'),\n",
       " Row(statut='éboueur'),\n",
       " Row(statut='professeur')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villes.select('statut').distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4) Union de dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ajouter les colonnes les unes à côté des autres : join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = villes.join(villes, on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=2, vitesse_a_pied=2.344207322136085, vitesse_a_velo=6.251219525696226, home='(lon:2.62 lat:2.59)', travail='(lon:2.34 lat:0.97)', sportif=False, casseur=False, statut='cadre', salaire=135167.36710061165, sexe='H', age=44, sportivite=7.814024407120282, velo_perf_minimale=0.4, vitesse_a_pied=2.344207322136085, vitesse_a_velo=6.251219525696226, home='(lon:2.62 lat:2.59)', travail='(lon:2.34 lat:0.97)', sportif=False, casseur=False, statut='cadre', salaire=135167.36710061165, sexe='H', age=44, sportivite=7.814024407120282, velo_perf_minimale=0.4),\n",
       " Row(id=3, vitesse_a_pied=0.02, vitesse_a_velo=0.05, home='(lon:3.79 lat:3.81)', travail='(lon:0.20 lat:0.21)', sportif=False, casseur=False, statut='technicien_de_surface', salaire=20026.72646423192, sexe='F', age=20, sportivite=0.1, velo_perf_minimale=0.4, vitesse_a_pied=0.02, vitesse_a_velo=0.05, home='(lon:3.79 lat:3.81)', travail='(lon:0.20 lat:0.21)', sportif=False, casseur=False, statut='technicien_de_surface', salaire=20026.72646423192, sexe='F', age=20, sportivite=0.1, velo_perf_minimale=0.4),\n",
       " Row(id=4, vitesse_a_pied=0.02, vitesse_a_velo=0.05, home='(lon:3.39 lat:0.93)', travail='(lon:0.58 lat:0.20)', sportif=False, casseur=False, statut='technicien_de_surface', salaire=15214.584161640825, sexe='F', age=35, sportivite=0.1, velo_perf_minimale=0.4, vitesse_a_pied=0.02, vitesse_a_velo=0.05, home='(lon:3.39 lat:0.93)', travail='(lon:0.58 lat:0.20)', sportif=False, casseur=False, statut='technicien_de_surface', salaire=15214.584161640825, sexe='F', age=35, sportivite=0.1, velo_perf_minimale=0.4),\n",
       " Row(id=5, vitesse_a_pied=0.030000000000000006, vitesse_a_velo=0.08, home='(lon:2.88 lat:3.78)', travail='(lon:3.38 lat:2.93)', sportif=False, casseur=False, statut='technicien_de_surface', salaire=18235.92844960795, sexe='H', age=71, sportivite=0.1, velo_perf_minimale=0.4, vitesse_a_pied=0.030000000000000006, vitesse_a_velo=0.08, home='(lon:2.88 lat:3.78)', travail='(lon:3.38 lat:2.93)', sportif=False, casseur=False, statut='technicien_de_surface', salaire=18235.92844960795, sexe='H', age=71, sportivite=0.1, velo_perf_minimale=0.4),\n",
       " Row(id=6, vitesse_a_pied=0.02, vitesse_a_velo=0.05, home='(lon:0.44 lat:1.45)', travail='(lon:1.85 lat:0.04)', sportif=False, casseur=False, statut='professeur', salaire=30852.120709809133, sexe='F', age=79, sportivite=0.1, velo_perf_minimale=0.4, vitesse_a_pied=0.02, vitesse_a_velo=0.05, home='(lon:0.44 lat:1.45)', travail='(lon:1.85 lat:0.04)', sportif=False, casseur=False, statut='professeur', salaire=30852.120709809133, sexe='F', age=79, sportivite=0.1, velo_perf_minimale=0.4)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ajouter les lignes les unes sous les autres : union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villes.unionByName(villes).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6) Concaténation de colonne : F.concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons ici reprendre le df cyclistes.\n",
    "\n",
    "Utiliser les méthodes withColumn() et F.concat() pour ajouter une colonne au df qui contiendra la concatenation des valeurs des colonnes id et sur_velo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2232000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./data/Cyclistes/*.csv\" \n",
    "cyclistes = spark.read.format(\"csv\").option(\"header\", \"true\").load(path, inferSchema=True)\n",
    "cyclistes.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+--------+-----+--------------------+-------------------+------------------+\n",
      "| id|          timestamp|sur_velo| velo|             vitesse|           position|destination_finale|\n",
      "+---+-------------------+--------+-----+--------------------+-------------------+------------------+\n",
      "| 12|2018-01-01 00:01:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|\n",
      "| 12|2018-01-01 00:02:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|\n",
      "| 12|2018-01-01 00:03:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|\n",
      "| 12|2018-01-01 00:04:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|\n",
      "| 12|2018-01-01 00:05:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|\n",
      "| 12|2018-01-01 00:06:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|\n",
      "| 12|2018-01-01 00:07:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|\n",
      "| 12|2018-01-01 00:08:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|\n",
      "| 12|2018-01-01 00:09:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|\n",
      "| 12|2018-01-01 00:10:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|\n",
      "+---+-------------------+--------+-----+--------------------+-------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cyclistes.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+--------+-----+--------------------+-------------------+------------------+-----------+\n",
      "| id|          timestamp|sur_velo| velo|             vitesse|           position|destination_finale|id_sur_velo|\n",
      "+---+-------------------+--------+-----+--------------------+-------------------+------------------+-----------+\n",
      "| 12|2018-01-01 00:01:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|    12false|\n",
      "| 12|2018-01-01 00:02:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|    12false|\n",
      "| 12|2018-01-01 00:03:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|    12false|\n",
      "| 12|2018-01-01 00:04:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|    12false|\n",
      "| 12|2018-01-01 00:05:00|   false|False|0.030000000000000006|(lon:2.07 lat:1.24)|             False|    12false|\n",
      "+---+-------------------+--------+-----+--------------------+-------------------+------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cyclistes.withColumn(\"id_sur_velo\", F.concat(cyclistes.id, cyclistes.sur_velo)).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Fonctions udf \n",
    "Il est possible d'enregistrer des fonctions python que l'on écrit nous même pour les appliquer sur une colonne d'une dataframe, c'est ce qu'on appelle les udf, pour User Defined Functions.\n",
    "\n",
    "Voici une fonction qui prend en argument une colonne et calcule le carré des valeurs de cette colonne.\n",
    "Appliquez cette fonction sur la colonne salaire de votre df. Affichez le résultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "\n",
    "@udf(returnType = FloatType())\n",
    "def carre(colonne):\n",
    "    return colonne**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(carre(salaire)=18270216192.0),\n",
       " Row(carre(salaire)=401069760.0),\n",
       " Row(carre(salaire)=231483568.0),\n",
       " Row(carre(salaire)=332549088.0),\n",
       " Row(carre(salaire)=951853376.0),\n",
       " Row(carre(salaire)=2969691392.0),\n",
       " Row(carre(salaire)=1128804608.0),\n",
       " Row(carre(salaire)=139238304.0),\n",
       " Row(carre(salaire)=1097721600.0),\n",
       " Row(carre(salaire)=2885448704.0),\n",
       " Row(carre(salaire)=647486208.0),\n",
       " Row(carre(salaire)=1229584384.0),\n",
       " Row(carre(salaire)=5521772544.0),\n",
       " Row(carre(salaire)=2574637056.0),\n",
       " Row(carre(salaire)=442693760.0),\n",
       " Row(carre(salaire)=287179296.0),\n",
       " Row(carre(salaire)=488372224.0),\n",
       " Row(carre(salaire)=6955476480.0),\n",
       " Row(carre(salaire)=6151191552.0),\n",
       " Row(carre(salaire)=5757398016.0),\n",
       " Row(carre(salaire)=1513707392.0),\n",
       " Row(carre(salaire)=845977152.0),\n",
       " Row(carre(salaire)=15607006208.0),\n",
       " Row(carre(salaire)=279298720.0),\n",
       " Row(carre(salaire)=658956352.0),\n",
       " Row(carre(salaire)=332481376.0),\n",
       " Row(carre(salaire)=11568824320.0),\n",
       " Row(carre(salaire)=871186176.0),\n",
       " Row(carre(salaire)=731495360.0),\n",
       " Row(carre(salaire)=22112497664.0),\n",
       " Row(carre(salaire)=1202230528.0),\n",
       " Row(carre(salaire)=423060096.0),\n",
       " Row(carre(salaire)=295006688.0),\n",
       " Row(carre(salaire)=1184019968.0),\n",
       " Row(carre(salaire)=229316384.0),\n",
       " Row(carre(salaire)=4948908544.0),\n",
       " Row(carre(salaire)=880376512.0),\n",
       " Row(carre(salaire)=993021504.0),\n",
       " Row(carre(salaire)=332946784.0),\n",
       " Row(carre(salaire)=155353856.0),\n",
       " Row(carre(salaire)=375707488.0),\n",
       " Row(carre(salaire)=421229280.0),\n",
       " Row(carre(salaire)=454536128.0),\n",
       " Row(carre(salaire)=5381703680.0),\n",
       " Row(carre(salaire)=596220544.0),\n",
       " Row(carre(salaire)=948523328.0),\n",
       " Row(carre(salaire)=147226240.0),\n",
       " Row(carre(salaire)=90477104.0),\n",
       " Row(carre(salaire)=988872128.0),\n",
       " Row(carre(salaire)=580938816.0)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villes.select(carre(\"salaire\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
