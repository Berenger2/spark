{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9182a66",
   "metadata": {},
   "source": [
    "# Projet Apache Spark : Analyse des données climatiques mondiales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b597f527",
   "metadata": {},
   "source": [
    "## Objectif :\n",
    "Analyser les tendances climatiques mondiales à l'aide de Spark, y compris le nettoyage des données, l'EDA et l'extraction d'informations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3a44b6",
   "metadata": {},
   "source": [
    "### Jeu de données :\n",
    "[Global Surface Summary of the Day (GSOD) provenant de NOAA](https://www.ncei.noaa.gov/access/metadata/landing-page/bin/iso?id=gov.noaa.ncdc:C00516)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2f1caaf-ff34-4fd4-9bbb-baf80c6c8cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "901c604b-f190-4427-83b8-3f1bc2d4b363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('STATION', 'string'), ('DATE', 'date'), ('LATITUDE', 'double'), ('LONGITUDE', 'double'), ('ELEVATION', 'double'), ('NAME', 'string'), ('TEMP', 'double'), ('TEMP_ATTRIBUTES', 'double'), ('DEWP', 'double'), ('DEWP_ATTRIBUTES', 'double'), ('SLP', 'double'), ('SLP_ATTRIBUTES', 'double'), ('STP', 'double'), ('STP_ATTRIBUTES', 'double'), ('VISIB', 'double'), ('VISIB_ATTRIBUTES', 'double'), ('WDSP', 'double'), ('WDSP_ATTRIBUTES', 'double'), ('MXSPD', 'double'), ('GUST', 'double'), ('MAX', 'double'), ('MAX_ATTRIBUTES', 'string'), ('MIN', 'double'), ('MIN_ATTRIBUTES', 'string'), ('PRCP', 'double'), ('PRCP_ATTRIBUTES', 'string'), ('SNDP', 'double'), ('FRSHTT', 'int')]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Créer ou obtenir une session Spark active\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Meteo Analysis\") \\\n",
    "    .config(\"spark.network.timeout\", \"14400s\") \\\n",
    "    .config(\"spark.executor.memory\", \"10g\") \\\n",
    "    .config(\"spark.driver.memory\", \"10g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Définir le chemin vers les fichiers CSV contenant les données des cyclistes\n",
    "path = \"./data/*/*.csv\"\n",
    "\n",
    "# Charger les données CSV dans un DataFrame Spark\n",
    "climat = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(path)\n",
    "\n",
    "# Afficher les types de données (schéma) de chaque colonne dans le DataFrame\n",
    "print(climat.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56df410b",
   "metadata": {},
   "source": [
    "---\n",
    "## Exploration du jeu de données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae49c784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données\n",
    "# Charger le jeu de données GSOD dans Spark en tant que DataFrame (Remplacer par le chemin réel)\n",
    "# df = spark.read.csv('chemin/vers/dataset.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58f65097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- STATION: string (nullable = true)\n",
      " |-- DATE: date (nullable = true)\n",
      " |-- LATITUDE: double (nullable = true)\n",
      " |-- LONGITUDE: double (nullable = true)\n",
      " |-- ELEVATION: double (nullable = true)\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- TEMP: double (nullable = true)\n",
      " |-- TEMP_ATTRIBUTES: double (nullable = true)\n",
      " |-- DEWP: double (nullable = true)\n",
      " |-- DEWP_ATTRIBUTES: double (nullable = true)\n",
      " |-- SLP: double (nullable = true)\n",
      " |-- SLP_ATTRIBUTES: double (nullable = true)\n",
      " |-- STP: double (nullable = true)\n",
      " |-- STP_ATTRIBUTES: double (nullable = true)\n",
      " |-- VISIB: double (nullable = true)\n",
      " |-- VISIB_ATTRIBUTES: double (nullable = true)\n",
      " |-- WDSP: double (nullable = true)\n",
      " |-- WDSP_ATTRIBUTES: double (nullable = true)\n",
      " |-- MXSPD: double (nullable = true)\n",
      " |-- GUST: double (nullable = true)\n",
      " |-- MAX: double (nullable = true)\n",
      " |-- MAX_ATTRIBUTES: string (nullable = true)\n",
      " |-- MIN: double (nullable = true)\n",
      " |-- MIN_ATTRIBUTES: string (nullable = true)\n",
      " |-- PRCP: double (nullable = true)\n",
      " |-- PRCP_ATTRIBUTES: string (nullable = true)\n",
      " |-- SNDP: double (nullable = true)\n",
      " |-- FRSHTT: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19622973, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspection du schéma et calcul des statistiques\n",
    "climat.printSchema()\n",
    "climat.count(), len(climat.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757eec73",
   "metadata": {},
   "source": [
    "**Questions :**\n",
    "1. Combien d'enregistrements contient le jeu de données ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccada236-c5fe-479c-8193-9147c943d0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19622973"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climat.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81cb05a-f1be-4d9d-a59b-12cbf6c05a3c",
   "metadata": {},
   "source": [
    "\n",
    "2. Quels sont les noms et types de colonnes ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fca2755a-854d-4cfe-aeca-422fa22c7242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- STATION: string (nullable = true)\n",
      " |-- DATE: date (nullable = true)\n",
      " |-- LATITUDE: double (nullable = true)\n",
      " |-- LONGITUDE: double (nullable = true)\n",
      " |-- ELEVATION: double (nullable = true)\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- TEMP: double (nullable = true)\n",
      " |-- TEMP_ATTRIBUTES: double (nullable = true)\n",
      " |-- DEWP: double (nullable = true)\n",
      " |-- DEWP_ATTRIBUTES: double (nullable = true)\n",
      " |-- SLP: double (nullable = true)\n",
      " |-- SLP_ATTRIBUTES: double (nullable = true)\n",
      " |-- STP: double (nullable = true)\n",
      " |-- STP_ATTRIBUTES: double (nullable = true)\n",
      " |-- VISIB: double (nullable = true)\n",
      " |-- VISIB_ATTRIBUTES: double (nullable = true)\n",
      " |-- WDSP: double (nullable = true)\n",
      " |-- WDSP_ATTRIBUTES: double (nullable = true)\n",
      " |-- MXSPD: double (nullable = true)\n",
      " |-- GUST: double (nullable = true)\n",
      " |-- MAX: double (nullable = true)\n",
      " |-- MAX_ATTRIBUTES: string (nullable = true)\n",
      " |-- MIN: double (nullable = true)\n",
      " |-- MIN_ATTRIBUTES: string (nullable = true)\n",
      " |-- PRCP: double (nullable = true)\n",
      " |-- PRCP_ATTRIBUTES: string (nullable = true)\n",
      " |-- SNDP: double (nullable = true)\n",
      " |-- FRSHTT: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "climat.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a070ec62-ebc2-4ccd-be79-a72b6eec1908",
   "metadata": {},
   "source": [
    "\n",
    "3. Combien de stations météorologiques uniques sont présentes ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c9260e7-587e-40d4-a222-829be79f35d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12948"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climat.select(\"STATION\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cf9add",
   "metadata": {},
   "source": [
    "---\n",
    "## Nettoyage des données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c12f080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifier les colonnes avec des valeurs manquantes et les traiter\n",
    "missing_values = climat.select([F.count(F.when(F.col(c).isNull(), c)) for c in climat.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "804cbcd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Supprimer les lignes avec des valeurs critiques manquantes\n",
    "climat_annee_delete = climat.dropna(subset=['TEMP', 'DATE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4c90c8",
   "metadata": {},
   "source": [
    "**Questions :**\n",
    "1. Quelles colonnes ont le plus de valeurs manquantes ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "329c2e8f-dc4b-4c5b-9f7b-2bd5cb4c4b52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'STATION': 0, 'DATE': 0, 'LATITUDE': 61659, 'LONGITUDE': 61659, 'ELEVATION': 63375, 'NAME': 61657, 'TEMP': 0, 'TEMP_ATTRIBUTES': 0, 'DEWP': 0, 'DEWP_ATTRIBUTES': 0, 'SLP': 0, 'SLP_ATTRIBUTES': 0, 'STP': 0, 'STP_ATTRIBUTES': 0, 'VISIB': 0, 'VISIB_ATTRIBUTES': 0, 'WDSP': 0, 'WDSP_ATTRIBUTES': 0, 'MXSPD': 0, 'GUST': 0, 'MAX': 0, 'MAX_ATTRIBUTES': 0, 'MIN': 0, 'MIN_ATTRIBUTES': 0, 'PRCP': 0, 'PRCP_ATTRIBUTES': 0, 'SNDP': 0, 'FRSHTT': 0}\n"
     ]
    }
   ],
   "source": [
    "# Calculer le nombre de valeurs manquantes pour chaque colonne\n",
    "missing_values = climat.select(\n",
    "    [count(when(col(c).isNull(), c)).alias(c) for c in climat.columns]\n",
    ")\n",
    "\n",
    "# Afficher chaque ligne (ici une seule ligne avec les résultats pour chaque colonne)\n",
    "for row in missing_values.collect():\n",
    "    print(row.asDict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d056c945-8a4d-4d87-b694-06a3e9cf2c6b",
   "metadata": {},
   "source": [
    "\n",
    "2. Après nettoyage, combien d'enregistrements restent ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75395215-416c-4a31-a41b-cb0202ecc74e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'enregistrements après nettoyage : 19559598\n"
     ]
    }
   ],
   "source": [
    "# Supprimer les lignes avec des valeurs manquantes dans n'importe quelle colonne\n",
    "drop_climat = climat.dropna()\n",
    "\n",
    "# Compter le nombre d'enregistrements restants après nettoyage\n",
    "remaining_records = drop_climat.count()\n",
    "\n",
    "print(f\"Nombre d'enregistrements après nettoyage : {remaining_records}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb73812-157b-4c2a-9893-4aefd63c654e",
   "metadata": {},
   "source": [
    "\n",
    "3. Quelle technique avez-vous utilisée pour traiter les valeurs manquantes dans la colonne des précipitations ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34c12800-6682-4053-8b45-7e4e32066050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'enregistrements après nettoyage : 19622973\n"
     ]
    }
   ],
   "source": [
    "#Pour l'ensemble de notre étude, nous avons choisi d'adopter la méthode d'imputation des \n",
    "#valeurs manquantes en utilisant une valeur fixe, telle que la moyenne, la médiane, ou d'autres \n",
    "#valeurs appropriées.\n",
    "\n",
    "# Récupérer la liste des colonnes numériques\n",
    "numeric_columns = [field.name for field in climat.schema.fields if isinstance(field.dataType, (IntegerType, DoubleType))]\n",
    "\n",
    "# Calculer la moyenne de chaque colonne numérique et remplir les valeurs manquantes\n",
    "mean_values = climat.select([F.mean(c).alias(c) for c in numeric_columns]).collect()[0].asDict()\n",
    "\n",
    "# Remplacer les valeurs manquantes pour chaque colonne par la moyenne\n",
    "climat_cleaned = climat.fillna(mean_values)\n",
    "\n",
    "# Afficher le nombre d'enregistrements après nettoyage\n",
    "remaining_records = climat_cleaned.count()\n",
    "print(f\"Nombre d'enregistrements après nettoyage : {remaining_records}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3c32d6",
   "metadata": {},
   "source": [
    "---\n",
    "## Transformation des données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2076a05-04ee-45d8-a018-a6a25dcda137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+\n",
      "|TEMP|TEMP_C|\n",
      "+----+------+\n",
      "|63.3|  17.4|\n",
      "|65.0|  18.3|\n",
      "|42.6|   5.9|\n",
      "|26.9|  -2.8|\n",
      "|34.4|   1.3|\n",
      "|44.2|   6.8|\n",
      "|35.3|   1.8|\n",
      "|26.9|  -2.8|\n",
      "|40.0|   4.4|\n",
      "|43.7|   6.5|\n",
      "|30.0|  -1.1|\n",
      "|31.8|  -0.1|\n",
      "|38.0|   3.3|\n",
      "|42.0|   5.6|\n",
      "|32.7|   0.4|\n",
      "|25.2|  -3.8|\n",
      "|34.7|   1.5|\n",
      "|33.6|   0.9|\n",
      "|36.6|   2.6|\n",
      "|40.8|   4.9|\n",
      "+----+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Colonnes restantes : ['STATION', 'DATE', 'LATITUDE', 'LONGITUDE', 'ELEVATION', 'NAME', 'TEMP', 'DEWP', 'SLP', 'STP', 'VISIB', 'WDSP', 'MXSPD', 'GUST', 'MAX', 'MIN', 'PRCP', 'SNDP', 'FRSHTT', 'TEMP_C']\n"
     ]
    }
   ],
   "source": [
    "def remove_unwanted_columns(climat_cleaned: DataFrame, columns_to_remove: list) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Supprime les colonnes spécifiées d'un DataFrame PySpark.\n",
    "    \n",
    "    :param df: DataFrame d'entrée\n",
    "    :param columns_to_remove: Liste des colonnes à supprimer\n",
    "    :return: DataFrame nettoyé sans les colonnes spécifiées\n",
    "    \"\"\"\n",
    "    return climat_cleaned.drop(*columns_to_remove)\n",
    "\n",
    "# Liste des colonnes à supprimer\n",
    "columns_to_remove = [\n",
    "    \"TEMP_ATTRIBUTES\",\n",
    "    \"DEWP_ATTRIBUTES\",\n",
    "    \"SLP_ATTRIBUTES\",\n",
    "    \"STP_ATTRIBUTES\",\n",
    "    \"VISIB_ATTRIBUTES\",\n",
    "    \"WDSP_ATTRIBUTES\",\n",
    "    \"MAX_ATTRIBUTES\",\n",
    "    \"MIN_ATTRIBUTES\",\n",
    "    \"PRCP_ATTRIBUTES\"\n",
    "]\n",
    "\n",
    "# Suppression des colonnes dans le DataFrame climat\n",
    "climat_col_cleaned = remove_unwanted_columns(climat_cleaned, columns_to_remove)\n",
    "#Rajout de la colonne Celcius\n",
    "climat_col_cleaned = climat_col_cleaned.withColumn(\"TEMP_C\", bround((col(\"TEMP\") - 32) / 1.8, 1))\n",
    " \n",
    "# Afficher le DataFrame avec les colonnes 'TEMP' et 'TEMP_C' arrondies\n",
    "climat_col_cleaned.select(\"TEMP\", \"TEMP_C\").show()\n",
    "# Afficher les colonnes restantes pour vérifier\n",
    "print(\"Colonnes restantes :\", climat_col_cleaned.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7476c0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+----------+---------+--------------------+----+----+------+-----+-----+----+-----+-----+----+----+----+-----+------+------+----+-----+---+------+\n",
      "|    STATION|      DATE| LATITUDE| LONGITUDE|ELEVATION|                NAME|TEMP|DEWP|   SLP|  STP|VISIB|WDSP|MXSPD| GUST| MAX| MIN|PRCP| SNDP|FRSHTT|TEMP_C|year|month|day|is_hot|\n",
      "+-----------+----------+---------+----------+---------+--------------------+----+----+------+-----+-----+----+-----+-----+----+----+----+-----+------+------+----+-----+---+------+\n",
      "|72401599999|2022-01-01|37.074194|-77.957528|    133.8|ALLEN C PERKINSON...|63.3|60.7|9999.9|999.9|  9.5| 8.5| 15.0| 25.1|75.2|53.1| 0.0|999.9| 10000|  17.4|2022|    1|  1| false|\n",
      "|72401599999|2022-01-02|37.074194|-77.957528|    133.8|ALLEN C PERKINSON...|65.0|61.2|9999.9|999.9|  9.5|10.5| 21.0| 28.9|75.2|56.1|0.29|999.9| 10000|  18.3|2022|    1|  2| false|\n",
      "|72401599999|2022-01-03|37.074194|-77.957528|    133.8|ALLEN C PERKINSON...|42.6|41.8|1013.3|999.9|  5.9|11.1| 22.9| 32.1|70.5|29.5|1.79|999.9|111000|   5.9|2022|    1|  3| false|\n",
      "|72401599999|2022-01-04|37.074194|-77.957528|    133.8|ALLEN C PERKINSON...|26.9|23.6|9999.9|999.9|  8.4| 1.5|  5.1|999.9|35.4|17.6|0.59|999.9|100000|  -2.8|2022|    1|  4| false|\n",
      "|72401599999|2022-01-05|37.074194|-77.957528|    133.8|ALLEN C PERKINSON...|34.4|32.5|9999.9|999.9|  9.8| 2.7|  8.9| 14.0|46.9|17.8| 0.0|999.9| 11000|   1.3|2022|    1|  5| false|\n",
      "|72401599999|2022-01-06|37.074194|-77.957528|    133.8|ALLEN C PERKINSON...|44.2|33.2|9999.9|999.9| 10.0| 5.1|  8.9|999.9|54.7|26.6| 0.0|999.9|     0|   6.8|2022|    1|  6| false|\n",
      "|72401599999|2022-01-07|37.074194|-77.957528|    133.8|ALLEN C PERKINSON...|35.3|22.8|9999.9|999.9|  9.7| 8.5| 21.0| 24.1|54.7|26.8| 0.0|999.9| 10000|   1.8|2022|    1|  7| false|\n",
      "|72401599999|2022-01-08|37.074194|-77.957528|    133.8|ALLEN C PERKINSON...|26.9| 9.3|9999.9|999.9| 10.0| 3.8|  8.0|999.9|43.2|18.1| 0.0|999.9|     0|  -2.8|2022|    1|  8| false|\n",
      "|72401599999|2022-01-09|37.074194|-77.957528|    133.8|ALLEN C PERKINSON...|40.0|26.5|9999.9|999.9|  9.9| 7.7| 21.0| 28.0|63.9|18.1|0.15|999.9| 10000|   4.4|2022|    1|  9| false|\n",
      "|72401599999|2022-01-10|37.074194|-77.957528|    133.8|ALLEN C PERKINSON...|43.7|30.2|9999.9|999.9|  9.7| 7.3| 19.0| 26.0|63.9|26.2|0.38|999.9| 10000|   6.5|2022|    1| 10| false|\n",
      "|72401599999|2022-01-11|37.074194|-77.957528|    133.8|ALLEN C PERKINSON...|30.0|10.4|9999.9|999.9| 10.0| 4.3| 12.0| 17.1|35.8|22.3| 0.0|999.9|     0|  -1.1|2022|    1| 11| false|\n",
      "|72401599999|2022-01-12|37.074194|-77.957528|    133.8|ALLEN C PERKINSON...|31.8|14.1|9999.9|999.9| 10.0| 7.1| 15.0| 19.0|49.8|21.0| 0.0|999.9|     0|  -0.1|2022|    1| 12| false|\n",
      "|72401599999|2022-01-13|37.074194|-77.957528|    133.8|ALLEN C PERKINSON...|38.0|22.9|9999.9|999.9| 10.0| 2.8|  5.1|999.9|53.6|21.0| 0.0|999.9|     0|   3.3|2022|    1| 13| false|\n",
      "|72401599999|2022-01-14|37.074194|-77.957528|    133.8|ALLEN C PERKINSON...|42.0|29.6|9999.9|999.9| 10.0| 6.1| 14.0| 22.9|53.6|25.0| 0.0|999.9|     0|   5.6|2022|    1| 14| false|\n",
      "|72401599999|2022-01-15|37.074194|-77.957528|    133.8|ALLEN C PERKINSON...|32.7|18.2|9999.9|999.9| 10.0| 4.2| 12.0| 17.1|50.5|24.4| 0.0|999.9|     0|   0.4|2022|    1| 15| false|\n",
      "|72401599999|2022-01-16|37.074194|-77.957528|    133.8|ALLEN C PERKINSON...|25.2|13.6|1015.1|999.9|  7.6| 6.8| 17.1| 22.9|36.0|20.7|0.86|999.9|111000|  -3.8|2022|    1| 16| false|\n",
      "|72401599999|2022-01-17|37.074194|-77.957528|    133.8|ALLEN C PERKINSON...|34.7|27.8|9999.9|999.9|  9.4|13.7| 20.0| 29.9|38.8|20.7|0.04|999.9| 11000|   1.5|2022|    1| 17| false|\n",
      "|72401599999|2022-01-18|37.074194|-77.957528|    133.8|ALLEN C PERKINSON...|33.6|19.3|9999.9|999.9| 10.0| 7.6| 15.0| 22.0|42.3|23.2| 0.0|999.9|     0|   0.9|2022|    1| 18| false|\n",
      "|72401599999|2022-01-19|37.074194|-77.957528|    133.8|ALLEN C PERKINSON...|36.6|23.3|9999.9|999.9| 10.0| 6.3| 19.0| 25.1|55.0|23.0| 0.0|999.9|     0|   2.6|2022|    1| 19| false|\n",
      "|72401599999|2022-01-20|37.074194|-77.957528|    133.8|ALLEN C PERKINSON...|40.8|32.4|9999.9|999.9|  8.6| 6.5| 14.0| 21.0|55.0|23.2|0.22|999.9| 11000|   4.9|2022|    1| 20| false|\n",
      "+-----------+----------+---------+----------+---------+--------------------+----+----+------+-----+-----+----+-----+-----+----+----+----+-----+------+------+----+-----+---+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transformer le jeu de données\n",
    "# Ajouter de nouvelles colonnes pour l'année, le mois et le jour\n",
    "climat_transformed = (\n",
    "    climat_col_cleaned\n",
    "    .withColumn('year', F.year(F.col('DATE')))  # Extraire l'année\n",
    "    .withColumn('month', F.month(F.col('DATE')))  # Extraire le mois\n",
    "    .withColumn('day', F.dayofmonth(F.col('DATE')))  # Extraire le jour\n",
    ")\n",
    "\n",
    "# Classifier les jours chauds (les données sont en degrées F°)\n",
    "climat_transformed = climat_transformed.withColumn('is_hot', F.col('TEMP') > 68)\n",
    "\n",
    "climat_transformed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cfaab9",
   "metadata": {},
   "source": [
    "**Questions :**\n",
    "1. Quels sont les 5 premiers enregistrements après le parsing de la colonne `date` ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b560917-8db0-454d-91fe-9e9c7e192944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+----------+---------+--------------------+----+----+------+-----+-----+----+-----+-----+----+----+----+-----+------+------+----+-----+---+------+\n",
      "|    STATION|      DATE| LATITUDE| LONGITUDE|ELEVATION|                NAME|TEMP|DEWP|   SLP|  STP|VISIB|WDSP|MXSPD| GUST| MAX| MIN|PRCP| SNDP|FRSHTT|TEMP_C|year|month|day|is_hot|\n",
      "+-----------+----------+---------+----------+---------+--------------------+----+----+------+-----+-----+----+-----+-----+----+----+----+-----+------+------+----+-----+---+------+\n",
      "|72401599999|2022-01-01|37.074194|-77.957528|    133.8|ALLEN C PERKINSON...|63.3|60.7|9999.9|999.9|  9.5| 8.5| 15.0| 25.1|75.2|53.1| 0.0|999.9| 10000|  17.4|2022|    1|  1| false|\n",
      "|72401599999|2022-01-02|37.074194|-77.957528|    133.8|ALLEN C PERKINSON...|65.0|61.2|9999.9|999.9|  9.5|10.5| 21.0| 28.9|75.2|56.1|0.29|999.9| 10000|  18.3|2022|    1|  2| false|\n",
      "|72401599999|2022-01-03|37.074194|-77.957528|    133.8|ALLEN C PERKINSON...|42.6|41.8|1013.3|999.9|  5.9|11.1| 22.9| 32.1|70.5|29.5|1.79|999.9|111000|   5.9|2022|    1|  3| false|\n",
      "|72401599999|2022-01-04|37.074194|-77.957528|    133.8|ALLEN C PERKINSON...|26.9|23.6|9999.9|999.9|  8.4| 1.5|  5.1|999.9|35.4|17.6|0.59|999.9|100000|  -2.8|2022|    1|  4| false|\n",
      "|72401599999|2022-01-05|37.074194|-77.957528|    133.8|ALLEN C PERKINSON...|34.4|32.5|9999.9|999.9|  9.8| 2.7|  8.9| 14.0|46.9|17.8| 0.0|999.9| 11000|   1.3|2022|    1|  5| false|\n",
      "+-----------+----------+---------+----------+---------+--------------------+----+----+------+-----+-----+----+-----+-----+----+----+----+-----+------+------+----+-----+---+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "climat_transformed.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdf9774-5294-496d-94ab-68804fbfed8a",
   "metadata": {},
   "source": [
    "\n",
    "2. Combien de jours ont été classés comme 'chauds' ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e647ca6-d98e-4b08-baed-1c42f94a32a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de jours classés comme 'chauds' : 6799157\n"
     ]
    }
   ],
   "source": [
    "# Compter le nombre de jours chauds (is_hot = true)\n",
    "hot_days_count = climat_transformed.filter(F.col(\"is_hot\") == True).count()\n",
    "\n",
    "# Afficher le résultat\n",
    "print(f\"Nombre total de jours classés comme 'chauds' : {hot_days_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f34571e-833a-4cd1-89a1-e2d5cafa3532",
   "metadata": {},
   "source": [
    "\n",
    "3. Quelles transformations ont été appliquées au jeu de données ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d8a3a0-f137-4371-ac3a-1842b682f36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous avons supprimé les colonnes qui nous semblaient inutiles, géré les valeurs manquantes, \n",
    "#ajouté de nouvelles colonnes, et créé une colonne supplémentaire intitulée is_hot et une autre colonne pour\n",
    "# transformer les degrées Fahrenheit en degrées Celsius"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46cda7b",
   "metadata": {},
   "source": [
    "---\n",
    "##  Analyse exploratoire des données (EDA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eeaeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer les moyennes annuelles et autres statistiques\n",
    "# avg_temp_by_year = df_transformed.groupBy('year').avg('temperature')\n",
    "#avg_temp_by_year.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e459ceea",
   "metadata": {},
   "source": [
    "**Questions :**\n",
    "1. Quelle est la température moyenne mondiale pour 2020 ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d08c24e6-78fb-41ca-8f10-d6e4b4297b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+------------------------+\n",
      "|Mean_Temperature_Fahrenheit|Mean_Temperature_Celcius|\n",
      "+---------------------------+------------------------+\n",
      "|         55.551539799548614|      13.084178913164052|\n",
      "+---------------------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Définir le chemin vers les fichiers CSV contenant les données des cyclistes\n",
    "climat_2020 = climat_transformed.filter(F.col('year') == 2020)\n",
    "\n",
    "avg_temp_2020 = climat_2020.agg({\"TEMP\": \"mean\", \"TEMP_C\": \"mean\"}).withColumnRenamed(\"avg(TEMP)\", \"Mean_Temperature_Fahrenheit\") \\\n",
    "                                                                   .withColumnRenamed(\"avg(TEMP_C)\", \"Mean_Temperature_Celcius\")\n",
    "\n",
    "# Afficher les résultats\n",
    "avg_temp_2020.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1474b3-c5cf-436b-9d9c-1e18f40d8c07",
   "metadata": {},
   "source": [
    "\n",
    "2. Quelles sont les 5 stations ayant enregistré les températures moyennes les plus élevées, et où sont-elles situées ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96b5b420-11c0-4acc-8291-20b86742adcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+---------+-----------+---------------------------+------------------------+\n",
      "|    STATION|            NAME| LATITUDE|  LONGITUDE|Mean_Temperature_Fahrenheit|Mean_Temperature_Celcius|\n",
      "+-----------+----------------+---------+-----------+---------------------------+------------------------+\n",
      "|42770099999| NARSINGHPUR, IN|    22.95| 79.1833333|                      100.0|                    37.8|\n",
      "|61437099999|     AKJOUJT, MR|    19.75|-14.3666667|                      95.42|      35.239999999999995|\n",
      "|67976099999|      RUPIKE, ZI|   -20.55| 31.0833333|                       95.2|                    35.1|\n",
      "|41216599999|SIR ABU NAIR, AE|25.216778|  54.233778|                       94.8|                    34.9|\n",
      "|41216199999|AL HAMRA AUX, AE|24.073981|  52.463644|                       94.1|                    34.5|\n",
      "+-----------+----------------+---------+-----------+---------------------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculer la température moyenne par station et obtenir les autres informations\n",
    "avg_temp_by_station = climat_transformed.groupBy('STATION', 'NAME', 'LATITUDE', 'LONGITUDE').agg({\"TEMP\": \"mean\", \"TEMP_C\": \"mean\"}).withColumnRenamed(\"avg(TEMP)\", \"Mean_Temperature_Fahrenheit\") \\\n",
    "                                                                                                                                    .withColumnRenamed(\"avg(TEMP_C)\", \"Mean_Temperature_Celcius\")\n",
    "# Trier par température moyenne (ordre décroissant) et prendre les 5 premières stations\n",
    "top_5_stations = avg_temp_by_station.orderBy(col('Mean_Temperature_Fahrenheit').desc()).limit(5)\n",
    " \n",
    "# Afficher les résultats\n",
    "top_5_stations.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea7b273-ed19-4c65-8fe1-3adc0bf0456e",
   "metadata": {},
   "source": [
    "\n",
    "3. Comment les précipitations mondiales ont-elles changé au cours des 50 dernières années ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78288bc2-9ac2-41e7-82cc-ec44f3f98b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|year| total_precipitation|\n",
      "+----+--------------------+\n",
      "|2020| 3.088141948999998E7|\n",
      "|2021|3.0669664580000024E7|\n",
      "|2022|3.1215037149999894E7|\n",
      "|2023|3.3003350469999846E7|\n",
      "|2024|2.7592773610000014E7|\n",
      "+----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# Calculer la somme des précipitations mondiales par année\n",
    "# Calculer la température moyenne par station et obtenir les autres informations\n",
    "total_precipitation = climat_transformed.groupBy('year').agg({\"PRCP\": \"sum\"}).withColumnRenamed(\"sum(PRCP)\", \"total_precipitation\")\n",
    "                                                                                                                                \n",
    "# Trier par température moyenne (ordre décroissant) et prendre les 5 premières stations\n",
    "precip_by_year = total_precipitation.orderBy(col('year').desc()).limit(50)\n",
    "\n",
    "# Afficher l'évolution des précipitations par année\n",
    "precip_by_year.orderBy('year').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f583ead3",
   "metadata": {},
   "source": [
    "---\n",
    "## Requêtes avancées\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432c9faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enregistrer comme vue SQL temporaire et exécuter des requêtes\n",
    "climat_transformed.createOrReplaceTempView('climate')\n",
    "# spark.sql('SELECT ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c008dab",
   "metadata": {},
   "source": [
    "**Questions :**\n",
    "1. Quelle a été l'année la plus froide enregistrée, et quelle était la température moyenne ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b08fe7d-ecac-441f-a7d7-573d6cc73b4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[TABLE_OR_VIEW_NOT_FOUND] The table or view `climate` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 3 pos 9;\n'GlobalLimit 1\n+- 'LocalLimit 1\n   +- 'Sort ['Mean_Temperature_Fahrenheit ASC NULLS FIRST], true\n      +- 'Aggregate ['year], ['year, 'AVG('TEMP) AS Mean_Temperature_Fahrenheit#1778, 'AVG('TEMP_C) AS Mean_Temperature_Celcius#1779]\n         +- 'UnresolvedRelation [climate], [], false\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Calculer la température moyenne par année\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m coldest_month \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'''\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;43m    SELECT year, AVG(TEMP) AS Mean_Temperature_Fahrenheit, AVG(TEMP_C) AS Mean_Temperature_Celcius\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;43m    FROM climate\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;43m    GROUP BY year\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;43m    ORDER BY Mean_Temperature_Fahrenheit ASC\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;43m    LIMIT 1\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;43m'''\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Afficher le mois le plus froid et sa température moyenne\u001b[39;00m\n\u001b[1;32m     11\u001b[0m coldest_month\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py:1631\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1627\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m         litArgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mtoArray(\n\u001b[1;32m   1629\u001b[0m             [_to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m [])]\n\u001b[1;32m   1630\u001b[0m         )\n\u001b[0;32m-> 1631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlitArgs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1632\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1633\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [TABLE_OR_VIEW_NOT_FOUND] The table or view `climate` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 3 pos 9;\n'GlobalLimit 1\n+- 'LocalLimit 1\n   +- 'Sort ['Mean_Temperature_Fahrenheit ASC NULLS FIRST], true\n      +- 'Aggregate ['year], ['year, 'AVG('TEMP) AS Mean_Temperature_Fahrenheit#1778, 'AVG('TEMP_C) AS Mean_Temperature_Celcius#1779]\n         +- 'UnresolvedRelation [climate], [], false\n"
     ]
    }
   ],
   "source": [
    "# Calculer la température moyenne par année\n",
    "coldest_month = spark.sql('''\n",
    "    SELECT year, AVG(TEMP) AS Mean_Temperature_Fahrenheit, AVG(TEMP_C) AS Mean_Temperature_Celcius\n",
    "    FROM climate\n",
    "    GROUP BY year\n",
    "    ORDER BY Mean_Temperature_Fahrenheit ASC\n",
    "    LIMIT 1\n",
    "''')\n",
    "\n",
    "# Afficher le mois le plus froid et sa température moyenne\n",
    "coldest_month.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0187b6-b594-4b9c-b94e-c62dcc17da60",
   "metadata": {},
   "source": [
    "\n",
    "2. Quelle station a contribué avec le plus grand nombre d'enregistrements ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b13a42d8-2b74-4516-8d0e-ba42a53d58a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[TABLE_OR_VIEW_NOT_FOUND] The table or view `climate` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 3 pos 9;\n'GlobalLimit 1\n+- 'LocalLimit 1\n   +- 'Sort ['Nombre_Enregistrement DESC NULLS LAST], true\n      +- 'Aggregate ['STATION, 'NAME], ['STATION, 'NAME, count(1) AS Nombre_Enregistrement#1780L]\n         +- 'UnresolvedRelation [climate], [], false\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Trouver la station avec le plus grand nombre d'enregistrements\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m most_records_station \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'''\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;43m    SELECT STATION, NAME, COUNT(*) AS Nombre_Enregistrement\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;43m    FROM climate\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;43m    GROUP BY STATION, NAME\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;43m    ORDER BY Nombre_Enregistrement DESC\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;43m    LIMIT 1\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;43m'''\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Afficher le résultat\u001b[39;00m\n\u001b[1;32m     11\u001b[0m most_records_station\u001b[38;5;241m.\u001b[39mshow(truncate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py:1631\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1627\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m         litArgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mtoArray(\n\u001b[1;32m   1629\u001b[0m             [_to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m [])]\n\u001b[1;32m   1630\u001b[0m         )\n\u001b[0;32m-> 1631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlitArgs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1632\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1633\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [TABLE_OR_VIEW_NOT_FOUND] The table or view `climate` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 3 pos 9;\n'GlobalLimit 1\n+- 'LocalLimit 1\n   +- 'Sort ['Nombre_Enregistrement DESC NULLS LAST], true\n      +- 'Aggregate ['STATION, 'NAME], ['STATION, 'NAME, count(1) AS Nombre_Enregistrement#1780L]\n         +- 'UnresolvedRelation [climate], [], false\n"
     ]
    }
   ],
   "source": [
    "# Trouver la station avec le plus grand nombre d'enregistrements\n",
    "most_records_station = spark.sql('''\n",
    "    SELECT STATION, NAME, COUNT(*) AS Nombre_Enregistrement\n",
    "    FROM climate\n",
    "    GROUP BY STATION, NAME\n",
    "    ORDER BY Nombre_Enregistrement DESC\n",
    "    LIMIT 1\n",
    "''')\n",
    "\n",
    "# Afficher le résultat\n",
    "most_records_station.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35416693-8f0d-41e3-89e7-8bc0a3bf2cc5",
   "metadata": {},
   "source": [
    "\n",
    "3. Fournissez la requête SQL utilisée pour trouver les réponses ci-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc02e7a-5a1b-4274-9a88-19d50c06eca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pour trouver le mois le plus froid et la température moyenne :\n",
    "    #SELECT year, AVG(TEMP) AS Mean_Temperature_Fahrenheit, AVG(TEMP_C) AS Mean_Temperature_Celcius\n",
    "    #FROM climate\n",
    "    #GROUP BY year\n",
    "    #ORDER BY Mean_Temperature_Fahrenheit ASC\n",
    "    #LIMIT 1\n",
    "#Pour trouver la station avec le plus grand nombre d'enregistrements :\n",
    "    #SELECT STATION, NAME, COUNT(*) AS Nombre_Enregistrement\n",
    "    #FROM climate\n",
    "    #GROUP BY STATION, NAME\n",
    "    #ORDER BY Nombre_Enregistrement DESC\n",
    "    #LIMIT 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377309b5",
   "metadata": {},
   "source": [
    "---\n",
    "## Visualisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf473b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporter les données vers Pandas et créer des visualisations\n",
    "# import matplotlib.pyplot as plt\n",
    "# df_pandas = avg_temp_by_year.toPandas()\n",
    "# plt.plot(df_pandas['year'], df_pandas['avg_temperature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65291c69",
   "metadata": {},
   "source": [
    "**Questions :**\n",
    "1. Quelles tendances sont visibles dans le graphique des températures moyennes mondiales ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa38ac22-6016-4496-af34-2fda6963a2bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f04ef583-384d-41a5-9a06-89dfed52d408",
   "metadata": {},
   "source": [
    "\n",
    "2. Quelles anomalies sont présentes dans l'histogramme des précipitations ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd6f70f-dac0-4cfa-b359-25047ee11fec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8ff3fdf-2c1e-4a65-872c-2cfddebc28d0",
   "metadata": {},
   "source": [
    "\n",
    "3. Quelles analyses supplémentaires recommanderiez-vous en fonction des visualisations ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd6a021-d9f0-4ec9-8bbf-0cbd7da15416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "147bd6f6",
   "metadata": {},
   "source": [
    "---\n",
    "## Optimisation et réflexion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8cbf1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer le cache et le repartitionnement\n",
    "# df_transformed.cache()\n",
    "# df_repartitioned = df_transformed.repartition(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eda5aa6",
   "metadata": {},
   "source": [
    "**Questions :**\n",
    "1. Comment la mise en cache a-t-elle amélioré les performances de vos requêtes ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e55b7e-3870-4045-b6d3-57d4b6c3d7df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbf290de-1e69-4918-9d4b-c0ae8b3af692",
   "metadata": {},
   "source": [
    "\n",
    "2. Comment le repartitionnement a-t-il affecté le temps d'exécution des tâches ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a474e0-1b09-4854-a591-f07547eb1b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af5c1e3b-25fb-4885-ab37-d43848890cad",
   "metadata": {},
   "source": [
    "\n",
    "3. Résumez l'information la plus surprenante que vous avez dérivée du jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66454db5-bcb2-456a-9812-17086f3ee3ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
